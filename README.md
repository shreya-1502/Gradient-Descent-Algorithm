# Gradient-Descent-Algorithm
Given a cost or loss function J(θ), where θ represents the parameters of a model, the goal of gradient descent is to iteratively update the parameters in the opposite direction of the gradient of the cost function with respect to the parameters. The updates are performed until convergence or a specified number of iterations.
